{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a0ae9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "url = 'https://en.wikipedia.org/wiki/Main_Page'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "headers = []\n",
    "for i in range(1, 7):\n",
    "    headers.extend(soup.find_all(f'h{i}'))\n",
    "\n",
    "df = pd.DataFrame({'Headers': [header.text.strip() for header in headers],\n",
    "                   'Tag': [header.name for header in headers]})\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4037f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://www.imdb.com/chart/top/'\n",
    "response = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "movies = soup.select('td.titleColumn')\n",
    "ratings = soup.select('td.ratingColumn.imdbRating')\n",
    "movie_data = []\n",
    "for i in range(50):\n",
    "    name = movies[i].a.text\n",
    "    year = movies[i].span.text.strip('()')\n",
    "    rating = ratings[i].strong.text\n",
    "    movie_data.append({'Name': name, 'Year': year, 'Rating': rating})\n",
    "\n",
    "df = pd.DataFrame(movie_data)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787084a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://www.imdb.com/india/top-rated-indian-movies/'\n",
    "response = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "movies = soup.select('td.titleColumn')\n",
    "ratings = soup.select('td.ratingColumn.imdbRating')\n",
    "movie_data = []\n",
    "for i in range(50):\n",
    "    name = movies[i].a.text\n",
    "    year = movies[i].span.text.strip('()')\n",
    "    rating = ratings[i].strong.text\n",
    "    movie_data.append({'Name': name, 'Year': year, 'Rating': rating})\n",
    "\n",
    "df = pd.DataFrame(movie_data)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734f0fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://www.icc-cricket.com/rankings/mens/team-rankings/odi'\n",
    "response = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "table = soup.find('table', {'class': 'table'})\n",
    "\n",
    "rows = table.tbody.find_all('tr')\n",
    "\n",
    "teams = []\n",
    "matches = []\n",
    "points = []\n",
    "ratings = []\n",
    "\n",
    "\n",
    "for row in rows[:10]:\n",
    "    team = row.find('span', {'class': 'u-hide-phablet'}).text.strip()\n",
    "    teams.append(team)\n",
    "    \n",
    "    cells = row.find_all('td')\n",
    "    match = cells[1].text.strip()\n",
    "    matches.append(match)\n",
    "    point = cells[2].text.strip()\n",
    "    points.append(point)\n",
    "    rating = cells[3].text.strip()\n",
    "    ratings.append(rating)\n",
    "\n",
    "data = {'Team': teams, 'Matches': matches, 'Points': points, 'Ratings': ratings}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adef08be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://presidentofindia.nic.in/former-presidents.htm'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "names = []\n",
    "terms = []\n",
    "\n",
    "for article in soup.find_all('div', class_='presidentListing'):\n",
    "    name = article.find('h3').text.strip().split('(')[0].strip()\n",
    "    names.append(name)\n",
    "    term_of_office = article.find('p').text.strip()\n",
    "    terms.append(term_of_office.replace('Term of Office:', '').strip())\n",
    "    \n",
    "data = {'Name': names, 'Term of Office': terms}\n",
    "df = pd.DataFrame(data)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571486b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting'\n",
    "response = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(response.content)\n",
    "soup\n",
    "\n",
    "table = soup.find('table', {'class': 'table rankings-table'})\n",
    "\n",
    "rows = table.find_all('tr')\n",
    "\n",
    "batsmen = []\n",
    "teams = []\n",
    "ratings = []\n",
    "\n",
    "for row in rows[:10]:\n",
    "\n",
    "    batsman = row.find('td', {'class': 'table-body__cell rankings-table__name name'}).a.text.strip()\n",
    "    team = row.find('span', {'class': 'table-body__logo-text'}).text.strip()\n",
    "    batsmen.append(batsman)\n",
    "    teams.append(team)\n",
    "    \n",
    "    rating = row.find('td', {'class': 'table-body__cell rating'}).text.strip()\n",
    "    ratings.append(rating)\n",
    "\n",
    "data = {'Batsman': batsmen, 'Team': teams, 'Rating': ratings}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9319e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling'\n",
    "response = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "table = soup.find('table', {'class': 'table rankings-table'})\n",
    "\n",
    "rows = table.tbody.find_all('tr')\n",
    "\n",
    "bowlers = []\n",
    "teams = []\n",
    "ratings = []\n",
    "\n",
    "for row in rows[:10]:\n",
    "    \n",
    "    bowler = row.find('td', {'class': 'table-body__cell rankings-table__name name'}).a.text.strip()\n",
    "    team = row.find('span', {'class': 'table-body__logo-text'}).text.strip()\n",
    "    bowlers.append(bowler)\n",
    "    teams.append(team)\n",
    "    \n",
    "    rating = row.find('td', {'class': 'table-body__cell rating'}).text.strip()\n",
    "    ratings.append(rating)\n",
    "\n",
    "data = {'Bowler': bowlers, 'Team': teams, 'Rating': ratings}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e43416",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03cfa5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages=requests.get(\"https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles\")\n",
    "pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4877d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(pages.content)\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79d9f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_title= []\n",
    "for i in soup.find_all('h2',class_=\"sc-1qrq3sd-1 gRGSUS sc-1nmom32-0 sc-1nmom32-1 btcbYu goSKRg\"):\n",
    "    paper_title.append(i.text)\n",
    "paper_title\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e192415",
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = []\n",
    "for i in soup.find_all('span',class_=\"sc-1w3fpd7-0 dnCnAO\"):\n",
    "    authors.append(i.text)\n",
    "authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2c8b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "published_date = []\n",
    "for i in soup.find_all('span',class_=\"sc-1thf9ly-2 dvggWt\"):\n",
    "    published_date.append(i.text)\n",
    "published_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1a427e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df =pd.DataFrame({'paper_title':paper_title,'author':authors,'published_date':published_date})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acfd735",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9e8024",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages= requests.get('https://www.dineout.co.in/delhi-restaurants/buffet-special')\n",
    "pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4c60c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(pages.content)\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cff373",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrapping multiple titles\n",
    "titles=[]\n",
    "\n",
    "for love in soup.find_all('a',class_=\"restnt-name ellipsis\"):\n",
    "    titles.append(love.text)\n",
    "titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfe04fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "price=[]\n",
    "\n",
    "for love in soup.find_all('span',class_=\"double-line-ellipsis\"):\n",
    "    price.append(love.text)\n",
    "price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9260ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc=[]\n",
    "\n",
    "for love in soup.find_all('div',class_=\"restnt-loc ellipsis\"):\n",
    "    loc.append(love.text)\n",
    "loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb7a8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_url=[]\n",
    "for love in soup.find_all('img',class_=\"no-img\"):\n",
    "    image_url.append(love.get('data-src'))\n",
    "image_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08b6580",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df=pd.DataFrame({'titels':titles,'price':price,'location':loc,'image':image_url})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8414da1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
